[
  {
    "path": "posts/2021-10-15-graph-r-packages/",
    "title": "Probabilistic Graphical Modelling with bnlearn package",
    "description": {},
    "author": [
      {
        "name": "am-innocenter",
        "url": {}
      }
    ],
    "date": "2022-05-07",
    "categories": [
      "DAGs",
      "Bayesian networks",
      "R-packages"
    ],
    "contents": "\nAn analysis for R-Packages built for graphs\nDAGs are\n\n\n\n\n\n\n",
    "preview": "posts/2021-10-15-graph-r-packages/graph-r-packages_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2022-05-07T17:17:49+12:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2019-11-26-understanding-us-student-loan-debt/",
    "title": "Understanding US Student Loan Debt",
    "description": "Perform data visualization and determine the most preferred method of payment for student loans in the US.",
    "author": [],
    "date": "2019-11-26",
    "categories": [
      "TidyTuesday",
      "Data viz"
    ],
    "contents": "\nThis week the data was inspired from the Dignity\n& Debt project. This will help in understanding and spreading\nawareness around Student Loan debt. The data source is here\nThe objective for this is to perform data visualization and determine\nthe most preferred method of payment for student loans in the US. I will\nuse patchwork package to combine plots.\nLoading the data\n\nRows: 291\nColumns: 10\n$ agency_name        <chr> \"Account Control Technology, Inc.\", \"Alli…\n$ year               <int> 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 1…\n$ quarter            <int> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,…\n$ starting           <dbl> 5807704381, 3693337631, 2364391549, 70421…\n$ added              <dbl> 1040570567, NA, NA, NA, NA, NA, 104094670…\n$ total              <dbl> 122602642, 113326847, 83853003, 99643903,…\n$ consolidation      <dbl> 20081894, 11533809, 7377703, 3401361, 894…\n$ rehabilitation     <dbl> 90952573, 86967994, 64227391, 85960328, 5…\n$ voluntary_payments <dbl> 5485506.9, 4885225.1, 3939866.1, 2508999.…\n$ wage_garnishments  <dbl> 6082668, 9939819, 8308043, 7773214, 54738…\n\nOriginal data file can be accessed through the weekly TidyTuesday\nGithub reporsitory in this link\nand data source is here\nRenaming columns\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nagency_name\n\n\nTotal.starting\n\n\nTotal.added\n\n\nTotal.repaid\n\n\nConServe\n\n\n109.05668\n\n\n8.255166\n\n\n3.3928101\n\n\nAccount Control Technology, Inc. \n\n\n91.20824\n\n\n8.254341\n\n\n2.8479518\n\n\nFMS Investment Corp\n\n\n73.20214\n\n\n8.254231\n\n\n2.1526409\n\n\nGC Services LP\n\n\n70.19962\n\n\n8.254341\n\n\n1.8947032\n\n\nWindham Professionals, Inc. \n\n\n65.77404\n\n\n8.254018\n\n\n2.0332805\n\n\nImmediate Credit Recovery, Inc. \n\n\n50.69030\n\n\n9.148463\n\n\n1.1516027\n\n\nImmediate Credit Recovery\n\n\n40.24292\n\n\n3.300990\n\n\n0.8600955\n\n\nFMS\n\n\n37.40026\n\n\n0.000000\n\n\n0.9890860\n\n\nCoast Professional, Inc. \n\n\n36.48558\n\n\n9.477421\n\n\n1.1540227\n\n\nGC Services\n\n\n35.37406\n\n\n0.000000\n\n\n0.9639185\n\n\nCoast Professional Inc\n\n\n35.36888\n\n\n7.604481\n\n\n0.9776974\n\n\nNational Recoveries Inc\n\n\n34.37731\n\n\n7.211969\n\n\n0.6891628\n\n\nAction Financial Services\n\n\n33.65348\n\n\n6.487008\n\n\n0.7403217\n\n\nNational Recoveries, Inc. \n\n\n31.86218\n\n\n8.850182\n\n\n0.7083161\n\n\n\n\n\n",
    "preview": "posts/2019-11-26-understanding-us-student-loan-debt/understanding-us-student-loan-debt_files/figure-html5/unnamed-chunk-7-1.png",
    "last_modified": "2022-05-08T15:34:18+12:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2020-03-30-parkinjuries/",
    "title": "Amusement Park Injuries in TX, USA",
    "description": "Investigating how many injuries were recorded and the top causes of the injuries reported",
    "author": [],
    "date": "2019-09-19",
    "categories": [
      "TidyTuesday",
      "Data viz"
    ],
    "contents": "\nAmusement park injuries data is from data.world.\nThis is part of the weekly #TidyTuesday project aimed at the R ecosystem\non Twitter.\nThe data has a lot of text, inconsistent NAs and dates.\nObjectives\nClean the data\nPerform EDA and Data viz\nTo achieve the objectives we shall answer the following questions\nHow many injuries were recorded per year, per month?\nWhat kind of injuries were reported? What were the top causes of\ninjuries?\nWho were injured more? Children? Adults? Female/Girls?\nMale/Boys?\nLoading packages\n\n\n\n\n\n\n\nRows: 542\nColumns: 13\n$ injury_report_rec <dbl> 2032, 1897, 837, 99, 55, 780, 253, 253, 55…\n$ name_of_operation <chr> \"Skygroup Investments LLC DBA iFly Austin\"…\n$ city              <chr> \"Austin\", \"Galveston\", \"Grapevine\", \"San A…\n$ st                <chr> \"TX\", \"TX\", \"TX\", \"TX\", \"AZ\", \"TX\", \"TX\", …\n$ injury_date       <chr> \"2/12/2013\", \"3/2/2013\", \"3/3/2013\", \"3/3/…\n$ ride_name         <chr> \"I Fly\", \"Gulf Glider\", \"Howlin Tornado\", …\n$ serial_no         <chr> \"SV024\", \"GS-11-10-WG-14\", \"0643-C1-T1-TN6…\n$ gender            <chr> \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"M\", \"M…\n$ age               <chr> \"37\", \"43\", NA, \"51\", \"17\", \"40\", \"36\", \"2…\n$ body_part         <chr> \"Mouth\", \"Knee\", \"Right Shoulder\", \"Lower …\n$ alleged_injury    <chr> \"Student hit mouth on wall\", \"Alleged arth…\n$ cause_of_injury   <chr> \"Student attempted unfamiliar manuever\", \"…\n$ other             <chr> NA, \"Prior history of problems with this k…\n\n AZ  FL  TX \n  5   1 536 \n[1] \"F\" \"M\" NA  \"m\"\n\nData Cleaning\n\nWe shall drop data from the other states and only consider TX. Rename\nthe two factors of gender and drop NA Date and age is a character, we\nshall convert to date type and numeric respectively\n\n\n\n\nThe date has two types - excel numeric and mdy format. Using a\ntwo-step process; I converted the date using the janitor\npackage for the excel numeric and to dates from character using the\nlubridate package.\n\n\n\nData Viz\nHere we determine how many injuries were recorded per month and per\nyear. To analyse which months need extra attention because we expect\nmore injurries in the park during summer compared to winter.\n\n\n\nThe numer of injuries over the years have been decreasing\nsignificantly. This could be to a number of reasons. To speculate the\nleast we are getting better at control measures on the parks to avoid\ninjuries.\nTo answer how many injuries were recorded per month we utilized the\nmonth.abb built-in constant to rearrange months from Jan -\nDec\n\n\n\nAs we had pre-empted, June-Aug has the highest number of\ninjuries.\nWho got injured more? Male or female? children or adults?\n\n\n\nTrick I learned to pick the colors use\nggplot_build(plotname).\nChildren reported more injuries compared to adults. Females are\nslightly more by 5% compared to the males.\nAnalyse the cause of injuries and body parts affected below using\ntidytext.\n\n\n\nThe most injured parts are head and shoulder among children and\nteenagers. For the elderly > 50 years it is the neck and shoulder.\nMost adults will be in the park taking care of the younger ones - the\nmost injured body parts are shoulder and head.\n\n\n\nI wanted to determine the words that occur commonly in pairs and how\noften sequence of word1 and word 2 occurs\n\n\n\n#Learnings\n\nConverting excel numeric date format. Using tidytext, discovering\njanitor package,\n\nIn case you have feedback, questions, suggestions do not hesitate to\nleave a comment.\n\n\n\n",
    "preview": "posts/2020-03-30-parkinjuries/parkinjuries_files/figure-html5/unnamed-chunk-8-1.png",
    "last_modified": "2022-05-08T15:37:49+12:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2019-08-18-errorknitting/",
    "title": "Error Knitting: R markdown not knitting",
    "description": "Setting up .Rprofile",
    "author": [],
    "date": "2019-08-18",
    "categories": [
      "Errors",
      "R setup"
    ],
    "contents": "\nI was getting errors knitting .Rmarkdown or .Rmd files and the\nculprint was that I had multiple .Rprofiles in my Home and project\ndirectories. The error is as shown below\n\nEverytime I restarted the machine it was loading the previous\nworkspace with the following error.\n\nAt first I thought .RData was the culprint and I unliked it using\nunlink(“~/.RData”). It still did not solve the problem.\nI had updated to the latest Rversion and my first instinct was update\nlibraries, uninstall and reinstall R+Rstudio but still the error was\nthere anytime I tried knitting. I tried most suggestions provided such\nas including self_contained: no and even installed tinytex :\ntinytex::install_tinytex().\nSolution\n\nThe following solution was provided by Yihue Xie.\n\nFirst, I had to uncheck the Restore workspace in the Global settings\nas show below and checked if the project directory had any .Rprofile and\nset it according to this link.\nThe following are some great resources that helped me\nR\nsetup\nStartup\n- Rprofile\nFinally, I can run my files without any hustle. Thanks to the support\nof Yihue Xhie and Christopher Dervieux. They helped me figure out where\nthe problem was.\n\nIf you’d like to refer to the conversation, I lodged an issue to the\nRstudio community and Github here.\n\n\n\n\n",
    "preview": {},
    "last_modified": "2022-05-08T17:22:20+12:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-08-18-getting-started-with-a-blog/",
    "title": "Getting Started with a Blog",
    "description": "Setting up a blog in R studio with Blogdown, Hugo and continuous deployment with Github and Netlify.",
    "author": [],
    "date": "2019-08-18",
    "categories": [
      "Blogdown",
      "Netlify"
    ],
    "contents": "\nI have been creating this blog in my mind for months and hey I\nfinally did it!\nBelow I will show you how I set up my personal blog using R Blogdown,\nHugo, Github and Netlify. I will continuously update and improve it.\nComments or suggestions on how to improve it are welcome :-)\nTo begin with, you will need the following to set up your blog\n\nInstall Blogdown.\nSelect a Hugo theme.\nSet up blogdown\nCreate a Github repository for your website.\nSet up Netlify for continuous deployment\nContinue editing your blog and enjoy writing!!\n\nScroll down to unlock the bonus tip/idea :-)\n1. Installing Blogdown\nInstall blogdown in R studio from CRAN\ninstall.packages(\"blogdown\")\nOr, install from GitHub\nif (!requireNamespace(\"devtools\")) install.packages(\"devtools\") devtools::install_github(\"rstudio/blogdown\")\nMore\nhere : blogdown installation\n2. Selecting a Hugo Theme\nHugo is a lightweight engine that can be used to create static\nwebsites. Hugo uses Go library for its template engine. You\nwill be required to select a theme, here is the complete list. More on setting up\nHugo themes here.\n3. Set up Blogdown\nAfter selecting the Hugo theme, using R studio open a new project and\ndirectory: using File → New Project → New Directory → Website using\nBlogdown\n\n{r} # knitr::include_graphics(\"blogdown1.png\") #\nYou will be required to specify the directory name of the blog, the\nsubdirectory where the blog is going to be place and the theme you\nselected in step 2 above. Complete the set up by clicking create\nproject. More on blogdown Rstudio IDE here.\nYou can modify the config.toml file, create new posts…\nThe website created can be built interactively by using\nblogdown::serve_site() or clicking Addins as shown\n\nNow you can create a New Post by clicking New Post using\nthe Addins or new_post(title = 'xxx.md') for markdown post\nor new_post(title = 'xxxx.Rmd') for R markdown files.\nBlogdown Structure\nDepending on the theme selected, kindly note\n\nStatic folder : is the root folder for the new blog.\nThis is a perfect place to include the images folder or pdf/materials\nfolder.\nPublic folder : after building the website - the final\nrendered static HTML files and structure are stored here. This is the\nfolder that shall be uploaded to Github.\nTheme folder : all the formating for the Hugo theme you\nselected are stored here.\nContent folder : is the folder containing all the posts\nyou will create. Usually has some markdown or .Rmd from the example\nsite.\n\n4. Deployment with Github\nLog into Github and create a new repository - do not add a readme.md\nyet. I prefer this way so that I do not have to make a\ngit pull request.\n\nPush the existing website located in your local directory to the\nrepository using the command line as shown below - note to change the\nworking directory to public/ before initializing the GIT repository\ncd ../public. I noticed if the whole working directory is\nput on Github - you will be required to add a netlify.toml\nfile - not sure if it was the theme I was using back then or it is\nuniversal. Best practise is to upload public folder since\nit contains the rendered HTML files of your website.\nAfter changing to ../public folder where the HTML files\nare rendered do;\ngit init : to initialize the local\ndirectory/repository\ngit remote add origin https://github.com/username/repositoryname.git\n_for example https://github.com/innocenter/Another-Data-Enthusist.git_\ngit push -u origin master\nNow you can add a readme.md note. You will be required to pull(fetch\nand merge) the files if you add any file using Github online. Safe to\nupdate in local directory using git add readme then\ngit commit -m \"read me\".\n\nAlthough Github supports only Jekyly and not Hugo, you can publish\nstatic HTML pages. Reference the following link\n\n5. Continous deployment with\nNetlify\nNow worry not about having to upload the public folder to Netlify everytime. Connect the Github\nrepository and let Netlify continously deploy your website anytime you\nupdate.\nAnother route will be to skip Github but everytime you will have to\nupload the public folder to Netlify.\nLog in to Netlify create a new site using Github\n\nSelect Github and follow the steps to deploy the website - netlify\nwill turn to green if the deployment was a success.\n\nYou can edit the setting of your website name\n\nNow you are ready to role - update Github by adding any new files and\ncommitting the changes. Now you have a domain name\nwebsite.netlify.com- remember to edit the config.toml\nbaseurl which was set with a trailing backslash\nbaseurl = \"/\". Copy the name of the website and replace it\nas baseurl = \"https://name-of-website.netlify.com\" This is\nwhy\n\nThe only purpose for the baseurl field in the config is to define the\nfull base URL of your website for deployment purposes.” - @rdwatters\n\nAnd the bonus is!!!!\nAdding comment section\nusing Disquis\nYou can include comments in your new webiste. Yay!! Follow the\nfollowing reference How\nto install disqus on hugo that provides clear way to setup.\nWorking on a post\nand prefer to upload later?\nNo problem, if it is a markdown file, you can either\nCreate the content with a future or past publishDate\nvalue for example date : “2019-08-01” and publishDate:\n‘2020-03-04’\nCreate content with draft: true status\nOther useful\nresources for setting up a blog\nCreating a website can be messy. You will actually get a lot of\nerrors - The following resources might be useful. The helped me a\nlot.\nCreating\nthe blog\nBlogdown book\nby Yihui Xie, Amber Thomas, Alison Presmanes Hill\nBlogdown and\nHugo\nChange the baseurl after getting a domain name. More\nhere\nLong live Netlifly! here\nHappy blogging :-)\nFeel free to drop a comment or suggestion in the comment section.\n\n\n\n",
    "preview": {},
    "last_modified": "2022-05-08T14:38:35+12:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-03-30-eidobserved/",
    "title": "Data mining and wrangling : A case of Eid Occurance",
    "description": "Data mining with rvest; case study of Eid observations",
    "author": [],
    "date": "2019-06-05",
    "categories": [
      "Data Mining",
      "Data Viz"
    ],
    "contents": "\nFinally, Eid is here! Id-Ul-Fitr commonly known as Eid marks the end\nof fasting (Ramadhan) and is the first day of the Islamic month\nShawwal. I spent my weekend learning data mining with rvest and\nanalysing data for Eid observations.\nThe following link\ncontains information about Eid, its occurence of per Day, Month, year.\nFor today, I intend to only mine the table and explore.\nObjectives\nMine data - table - from a URL using the package rvest (this was\nmy first time and its really simple)\nExplore basic data cleaning using dplyr (this is included in\ntidyverse library)\nExplore the occurence of Eid i.e per month, per day\nPerform visualization using ggplot :-).\nThis is a learning curve and feel free to drop in your comments\nand/or suggestions. I will show you a bit of my thought process when\nanalysing and wrangling data.\nLet’s go 😄 💃\nSide note check this link and this to learn more\nabout including emojis in a markdown.\nLoading packages required\n\n\n\nData Mining\nLoading the data - but first we have to mine it from the URL\nprovided\n\n{xml_nodeset (3)}\n[1] <table class=\"tb-quick-facts\">\\n<tr>\\n<th>This year:<\/th>\\n<td> ...\n[2] <table id=\"tb-hol_obs\" class=\"tb-theme fw sep\">\\n<thead><tr>\\n< ...\n[3] <table class=\"tb-quick-facts\"><tbody>\\n<tr>\\n<th>English<\/th>\\n ...\n\nThere are 3 tables - no idea which one contains the Eid data. I will\nextract all the tables - out of curiosity and they’re only 3. If we had\nseveral tables - we could explicity use the table names e.g\nhtml_nodes(‘#table2’)\n\nList of 3\n $ : tibble [4 × 2] (S3: tbl_df/tbl/data.frame)\n  ..$ X1: chr [1:4] \"This year:\" \"Next year:\" \"Last year:\" \"Type:\"\n  ..$ X2: chr [1:4] \"Mon, 2 May 2022 Tue, 3 May 2022\" \"Sun, 23 Apr 2023\" \"Fri, 14 May 2021\" \"Public holiday\"\n $ : tibble [13 × 5] (S3: tbl_df/tbl/data.frame)\n  ..$ Year        : int [1:13] 2017 2018 2019 2020 2020 2021 2022 2022 2023 2024 ...\n  ..$ Weekday     : chr [1:13] \"Mon\" \"Sat\" \"Wed\" \"Sun\" ...\n  ..$ Date        : chr [1:13] \"26 Jun\" \"16 Jun\" \"5 Jun\" \"24 May\" ...\n  ..$ Name        : chr [1:13] \"Eid al-Fitr\" \"Eid al-Fitr\" \"Eid al-Fitr\" \"Eid al-Fitr\" ...\n  ..$ Holiday Type: chr [1:13] \"Public holiday\" \"Public holiday\" \"Public holiday\" \"Public holiday\" ...\n $ : tibble [4 × 2] (S3: tbl_df/tbl/data.frame)\n  ..$ X1: chr [1:4] \"English\" \"German\" \"Norwegian\" \"Swahili\"\n  ..$ X2: chr [1:4] \"Eid al-Fitr, End of Ramadan\" \"Eid al-Fitr (Fest des Fastenbrechens)\" \"Eid al-Fitr, Slutt på ramadan\" \"Idd el Fitr, Mwisho wa Ramadhani\"\n\nThe second table contains information we are interested in - it has\nEid occurance data from the year 2015 - 2025 (some are predictions).\n\n\n\nAnother method to extact the table is by creating an empty list and\npopulating it with data\n\n\n\nEDA and cleaning\n\ntibble [13 × 5] (S3: tbl_df/tbl/data.frame)\n $ Year        : int [1:13] 2017 2018 2019 2020 2020 2021 2022 2022 2023 2024 ...\n $ Weekday     : chr [1:13] \"Mon\" \"Sat\" \"Wed\" \"Sun\" ...\n $ Date        : chr [1:13] \"26 Jun\" \"16 Jun\" \"5 Jun\" \"24 May\" ...\n $ Name        : chr [1:13] \"Eid al-Fitr\" \"Eid al-Fitr\" \"Eid al-Fitr\" \"Eid al-Fitr\" ...\n $ Holiday Type: chr [1:13] \"Public holiday\" \"Public holiday\" \"Public holiday\" \"Public holiday\" ...\n\nThe data contains (13, 5) - that is 12 observations and 5\nvariables\nIn the year 2015 - there exists two entries the second one is the\nobserved and thus will delete the first entry\n\n\n\nFrom the structure above, we can see that the names of weekday is\nwritten in some language for example Sunday is J2 - I checked the\nEnglish equivalence in the website and replaced them.\nThe column names and data types are\n\n[1] \"Year\"         \"Weekday\"      \"Date\"         \"Name\"        \n[5] \"Holiday Type\"\n[1] \"integer\"   \"character\" \"character\"\n\nThe analysis will be based on the month and hence I separate the day\nfrom the month in column Date\n\n\n\nThe month of May is written as Mei - I replaced that and the weekday\nas shown below.\n\nFrom the website: Sun-J2, Mon-J3, Tue-J4, Wed-J5, Thu-Alh, Fri-Ij,\nSat-J1\n\n\n\n\nI had to do these one item after another - I will figure out a way\nnext time maybe a loop\nThe replace and gsub functions worked for just one\nitem - I tried concatinating the other and got an error while compiling\nor the matching was not exactly correct. I got this error with gsub\nargument ‘replacement’ has length > 1 and only the first element\nwill be used\nI also replaced the rest\nHere is our cleaned data\n\n# A tibble: 12 × 6\n    Year Weekday Day   Month Name                    `Holiday Type`\n   <int> <chr>   <chr> <chr> <chr>                   <chr>         \n 1  2018 Sat     16    Jun   Eid al-Fitr             Public holiday\n 2  2019 Wed     5     Jun   Eid al-Fitr             Public holiday\n 3  2020 Sun     24    May   Eid al-Fitr             Public holiday\n 4  2020 Mon     25    May   Day off for Eid al-Fitr Public holiday\n 5  2021 Fri     14    May   Eid al-Fitr             Public holiday\n 6  2022 Mon     2     May   Eid al-Fitr             Public holiday\n 7  2022 Tue     3     May   Eid al-Fitr Holiday     Public holiday\n 8  2023 Sun     23    Apr   Eid al-Fitr             Public holiday\n 9  2024 Thu     11    Apr   Eid al-Fitr             Public holiday\n10  2025 Tue     1     Apr   Eid al-Fitr             Public holiday\n11  2026 Sat     21    Mar   Eid al-Fitr             Public holiday\n12  2027 Thu     11    Mar   Eid al-Fitr             Public holiday\n\n\n# A tibble: 4 × 2\n  Month Month_occurence\n  <chr>           <int>\n1 Apr                 3\n2 Jun                 2\n3 Mar                 2\n4 May                 5\n\nFor the past 12 years each month has been represented three times except\nfor July.\n\n# A tibble: 7 × 2\n  Weekday Weekday_occurence\n  <chr>               <int>\n1 Fri                     1\n2 Mon                     2\n3 Sat                     2\n4 Sun                     2\n5 Thu                     2\n6 Tue                     2\n7 Wed                     1\n\nEid was observed mostly on Monday from the year 2015 - 2025 - this is\nthe future 😉\nVisualization\nOur fourth objective was to visualize the data and get an insight on\nthe month or day that Eid is observed for the 12 years.\n\n\n\n\n\n\n\nTake home notes : this was a refresher for me and aluta continua\n\nI hope you have enjoyed this - though short 😄\n\nFrom this data, the prediction is that next year - Eid will occur on\na Monday in the month of May - I shall sit tight and wait for it.\n\n\nHave a blessed Eid\n\n\n\n\n",
    "preview": "posts/2020-03-30-eidobserved/eidobserved_files/figure-html5/unnamed-chunk-16-1.png",
    "last_modified": "2022-05-08T16:53:41+12:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  }
]
